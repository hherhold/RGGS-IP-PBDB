{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inclusive-passage",
   "metadata": {},
   "source": [
    "# Occurrence data for Invertebrate Paleo Group Project, Spring 2021, AMNH RGGS\n",
    "\n",
    "This Jupyter notebook accesses data from the PaleoBioDB directly using URLs formatted freom the paleobiodb.org website.\n",
    "You should run what's in here already to see how it works before modifying for your own uses.\n",
    "\n",
    "This notebook is set up to create 3 CSV files, one each for the Kaili, Poleta, and Burgess Shale formations. It collates id names\n",
    "from columns in the DB and also makes a list of references from the database.\n",
    "\n",
    "*You can hit \"run all\" but it will take a minute or two.*\n",
    "\n",
    "## Load libraries.\n",
    "\n",
    "Some of this stuff is vestigial tails from other projects\n",
    "(for example, matplotlib isn't necessary but I'm leaving it in here out of habit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "answering-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-hartford",
   "metadata": {},
   "source": [
    "# PBDB Queries\n",
    "\n",
    "Load in PBDB occurrences from Asia and North America, from 520-500mya. These URLs are from the \"Download Records\"\n",
    "page on paleobiodb.org.\n",
    "\n",
    "The CSV files are cached in the filenames specified below. You can force downloading by either deleting the CSV files\n",
    "or by setting FORCE_DOWNLOAD below to True.\n",
    "\n",
    "*Note that the data download may take a minute or two.* Watch for the ampersand to turn to a number in the brackets for the cell, indicating that the cell is finished running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rapid-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_DOWNLOAD = False\n",
    "\n",
    "asia_520_500_pbdb_url = (\n",
    "    \"http://paleobiodb.org/data1.2/occs/list.csv?datainfo&rowcount&max_ma=520&min_ma=500&cc=ASI&\"\n",
    "    \"lithology=siliciclastic,mixed,carbonate,evaporite,organic,chemical,volcanic,metasedimentary,\"\n",
    "    \"metamorphic,other,unknown&envtype=terr,marine,carbonate,silicic,unknown,lacust,fluvial,karst,\"\n",
    "    \"terrother,marginal,reef,stshallow,stdeep,offshore,slope,marindet&show=full,genus,subgenus,strat,env,ref\"\n",
    ")\n",
    "asia_csv_filename = \"pbdb_asia_raw_520_500.csv\"\n",
    "    \n",
    "na_520_500_pbdb_url = (\n",
    "    \"http://paleobiodb.org/data1.2/occs/list.csv?datainfo&rowcount&max_ma=520&min_ma=500&cc=NOA&\"\n",
    "    \"lithology=siliciclastic,mixed,carbonate,evaporite,organic,chemical,volcanic,metasedimentary,\"\n",
    "    \"metamorphic,other,unknown&envtype=terr,marine,carbonate,silicic,unknown,lacust,fluvial,karst,\"\n",
    "    \"terrother,marginal,reef,stshallow,stdeep,offshore,slope,marindet&show=full,genus,subgenus,strat,env,ref\"\n",
    ")\n",
    "na_csv_filename = \"pbdb_na_raw_520_500.csv\"\n",
    "\n",
    "if (not os.path.exists(asia_csv_filename)) or FORCE_DOWNLOAD == True:\n",
    "    r = requests.get(asia_520_500_pbdb_url, allow_redirects=True)\n",
    "    open(asia_csv_filename, 'wb').write(r.content)\n",
    "\n",
    "if (not os.path.exists(na_csv_filename)) or FORCE_DOWNLOAD == True:\n",
    "    r = requests.get(na_520_500_pbdb_url, allow_redirects=True)\n",
    "    open(na_csv_filename, 'wb').write(r.content)\n",
    "\n",
    "# Kaili.\n",
    "pbdb_asia_occs_df = pd.read_csv(asia_csv_filename, \n",
    "                                low_memory=False, \n",
    "                                encoding='latin1',\n",
    "                                skiprows=21)\n",
    "kaili_occs_df = pbdb_asia_occs_df[pbdb_asia_occs_df.formation == 'Kaili']\n",
    "\n",
    "# Poleta.\n",
    "pbdb_na_occs_df = pd.read_csv(na_csv_filename, \n",
    "                              low_memory=False,\n",
    "                              encoding='latin1',\n",
    "                              skiprows=21)\n",
    "poleta_occs_df = pbdb_na_occs_df[pbdb_na_occs_df.formation == 'Poleta']\n",
    "\n",
    "# Burgess Shale.\n",
    "burgess_occs_df = pbdb_na_occs_df[pbdb_na_occs_df.formation == 'Burgess Shale']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-hindu",
   "metadata": {},
   "source": [
    "There are lots of columns. Like, *lots*. We will not use most of these, but here are some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "integral-idaho",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['occurrence_no', 'record_type', 'reid_no', 'flags', 'collection_no',\n",
       "       'identified_name', 'identified_rank', 'identified_no', 'difference',\n",
       "       'accepted_name',\n",
       "       ...\n",
       "       'ecospace_comments', 'composition', 'architecture', 'thickness',\n",
       "       'reinforcement', 'genus.1', 'formation.1', 'stratgroup.1', 'member.1',\n",
       "       'primary_reference'],\n",
       "      dtype='object', length=123)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "kaili_occs_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-retention",
   "metadata": {},
   "source": [
    "Now we want to get a list of just each taxon, which happens to be conveniently put in the \"identified_name\" column. This basically collapses all occurrences into a single taxon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "upper-panel",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Kaili taxa: 130\nPoleta taxa: 45\nBurgess Shale taxa: 279\n"
     ]
    }
   ],
   "source": [
    "kaili_id_name_set = set()\n",
    "for id_name in kaili_occs_df['identified_name']:\n",
    "    kaili_id_name_set.add(id_name)\n",
    "burgess_id_name_set = set()\n",
    "for id_name in burgess_occs_df['identified_name']:\n",
    "    burgess_id_name_set.add(id_name)\n",
    "\n",
    "poleta_id_name_set = set()\n",
    "for id_name in poleta_occs_df['identified_name']:\n",
    "    poleta_id_name_set.add(id_name)\n",
    "\n",
    "# Print how many in each.\n",
    "print(f'Kaili taxa: {len(kaili_id_name_set)}')\n",
    "print(f'Poleta taxa: {len(poleta_id_name_set)}')\n",
    "print(f'Burgess Shale taxa: {len(burgess_id_name_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-yorkshire",
   "metadata": {},
   "source": [
    "Now let's dump the taxonomic info for every one of these into a CSV file, along with references.\n",
    "\n",
    "First Kaili formation...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "regional-crossing",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Kaili done.\n"
     ]
    }
   ],
   "source": [
    "with open(\"kaili_pbdb_taxa.csv\", \"w\") as outfile:\n",
    "    print(\"phylum,class,order,family,genus,identified_name,references\", file=outfile)\n",
    "    for taxon in kaili_id_name_set:\n",
    "        # First let's get a list of all the references for this name. We don't want to dump\n",
    "        # lots of duplicate references, so we will use a set.\n",
    "        refs = kaili_occs_df.primary_reference[kaili_occs_df.identified_name == taxon]\n",
    "        ref_set = set()\n",
    "        for ref in refs:\n",
    "            ref_set.add(ref)\n",
    "\n",
    "        phylum = kaili_occs_df[kaili_occs_df['identified_name'] == taxon].iloc[0]['phylum']\n",
    "        tax_class = kaili_occs_df[kaili_occs_df['identified_name'] == taxon].iloc[0]['class']\n",
    "        order = kaili_occs_df[kaili_occs_df['identified_name'] == taxon].iloc[0]['order']\n",
    "        family = kaili_occs_df[kaili_occs_df['identified_name'] == taxon].iloc[0]['family']\n",
    "        genus = kaili_occs_df[kaili_occs_df['identified_name'] == taxon].iloc[0]['genus']\n",
    "\n",
    "        print(f'{phylum},{tax_class},{order},{family},{genus},{taxon},', file=outfile, end='')\n",
    "        for ref in ref_set:\n",
    "            # need to remove double quotes in titles.\n",
    "            ref = ref.replace('\"', \"'\")\n",
    "            print(f'\\\"{ref}\\\",', file=outfile, end='')\n",
    "        print('\\n', file=outfile, end='')\n",
    "print(\"Kaili done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-resolution",
   "metadata": {},
   "source": [
    "Poleta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "covered-heavy",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Poleta done.\n"
     ]
    }
   ],
   "source": [
    "with open(\"poleta_pbdb_taxa.csv\", \"w\") as outfile:\n",
    "    print(\"phylum,class,order,family,genus,identified_name,references\", file=outfile)\n",
    "    for taxon in poleta_id_name_set:\n",
    "        refs = poleta_occs_df.primary_reference[poleta_occs_df.identified_name == taxon]\n",
    "        ref_set = set()\n",
    "        for ref in refs:\n",
    "            ref_set.add(ref)\n",
    "        phylum = poleta_occs_df[poleta_occs_df['identified_name'] == taxon].iloc[0]['phylum']\n",
    "        tax_class = poleta_occs_df[poleta_occs_df['identified_name'] == taxon].iloc[0]['class']\n",
    "        order = poleta_occs_df[poleta_occs_df['identified_name'] == taxon].iloc[0]['order']\n",
    "        family = poleta_occs_df[poleta_occs_df['identified_name'] == taxon].iloc[0]['family']\n",
    "        genus = poleta_occs_df[poleta_occs_df['identified_name'] == taxon].iloc[0]['genus']\n",
    "\n",
    "        print(f'{phylum},{tax_class},{order},{family},{genus},{taxon},', file=outfile, end='')\n",
    "        for ref in ref_set:\n",
    "            # need to remove double quotes in titles.\n",
    "            ref = ref.replace('\"', \"'\")\n",
    "            print(f'\\\"{ref}\\\",', file=outfile, end='')\n",
    "        print('\\n', file=outfile, end='')\n",
    "print(\"Poleta done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-netherlands",
   "metadata": {},
   "source": [
    "Burgess shale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suspected-snowboard",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Burgess done.\n"
     ]
    }
   ],
   "source": [
    "with open(\"burgess_pbdb_taxa.csv\", \"w\") as outfile:\n",
    "    print(\"phylum,class,order,family,genus,identified_name,references\", file=outfile)\n",
    "    for taxon in burgess_id_name_set:\n",
    "        refs = burgess_occs_df.primary_reference[burgess_occs_df.identified_name == taxon]\n",
    "        ref_set = set()\n",
    "        for ref in refs:\n",
    "            ref_set.add(ref)\n",
    "        phylum = burgess_occs_df[burgess_occs_df['identified_name'] == taxon].iloc[0]['phylum']\n",
    "        tax_class = burgess_occs_df[burgess_occs_df['identified_name'] == taxon].iloc[0]['class']\n",
    "        order = burgess_occs_df[burgess_occs_df['identified_name'] == taxon].iloc[0]['order']\n",
    "        family = burgess_occs_df[burgess_occs_df['identified_name'] == taxon].iloc[0]['family']\n",
    "        genus = burgess_occs_df[burgess_occs_df['identified_name'] == taxon].iloc[0]['genus']\n",
    "\n",
    "        print(f'{phylum},{tax_class},{order},{family},{genus},{taxon},', file=outfile, end='')\n",
    "        for ref in ref_set:\n",
    "            # need to remove double quotes in titles.\n",
    "            ref = ref.replace('\"', \"'\")\n",
    "            print(f'\\\"{ref}\\\",', file=outfile, end='')\n",
    "        print('\\n', file=outfile, end='')\n",
    "print(\"Burgess done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-plasma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}